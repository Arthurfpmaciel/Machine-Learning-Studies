{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip training and testing data before running the notebook\n",
    "# imports\n",
    "import sys, os\n",
    "import warnings\n",
    "from math import log\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes model class\n",
    "class NB_Model:\n",
    "    spam_counts = {}\n",
    "    notspam_counts = {}\n",
    "    class_counts = {}\n",
    "    model_vocabulary_size = {}\n",
    "    \n",
    "    def build_word_counts_model(self,files_path):\n",
    "        # binary type: checks whether or not a word occurs in the document\n",
    "        # continuous type: check how many times a word occurs in the document\n",
    "        print(\"Counting words in train dataset...\")\n",
    "        dirs = os.listdir(files_path)\n",
    "        for class_dir_name in dirs:\n",
    "            for f in os.listdir(os.path.join(files_path, class_dir_name)):\n",
    "                document = os.path.join(files_path, class_dir_name, f)\n",
    "                with open(document, 'r', encoding = \"latin1\") as file:\n",
    "                    words = file.read().split()\n",
    "                    distinct_words = sorted(set(words))\n",
    "                    for word in distinct_words:\n",
    "\n",
    "                        self.class_counts[class_dir_name]['word_counts'][word]['frequency_count'] = \\\n",
    "                            self.class_counts\\\n",
    "                                .setdefault(class_dir_name,{})\\\n",
    "                                .setdefault('word_counts',{})\\\n",
    "                                .setdefault(word, {})\\\n",
    "                                .setdefault('frequency_count', 0) + words.count(word)\n",
    "                        self.class_counts[class_dir_name]['word_counts'][word]['presence_count'] = \\\n",
    "                            self.class_counts\\\n",
    "                                .setdefault(class_dir_name,{})\\\n",
    "                                .setdefault('word_counts',{})\\\n",
    "                                .setdefault(word, {})\\\n",
    "                                .setdefault('presence_count', 0) + 1\n",
    "                    self.class_counts[class_dir_name]['total_count'] = \\\n",
    "                        self.class_counts\\\n",
    "                            .setdefault(class_dir_name, {})\\\n",
    "                            .setdefault('total_count', 0) + 1\n",
    "                    pass\n",
    "            pass\n",
    "        spam_word_counts = self.class_counts[\"spam\"][\"word_counts\"]\n",
    "        notspam_word_counts = self.class_counts[\"notspam\"][\"word_counts\"]\n",
    "        least_associated_with_spam = {k:v for k,v in notspam_word_counts.items() if k not in spam_word_counts}\n",
    "        pass\n",
    "\n",
    "    def save_model_to_file(self,file_name):\n",
    "        print(\"Saving model in especified file...\")\n",
    "        if not os.path.exists(os.path.dirname(file_name)):\n",
    "            os.makedirs(os.path.dirname(file_name))\n",
    "        with open(file_name,'w+', encoding='utf-8') as filehandle:\n",
    "            json.dump({\"class_counts\":self.class_counts},filehandle,sort_keys=True,indent = 4, ensure_ascii=False)\n",
    "    \n",
    "    def train(self,files_path,model_file):\n",
    "        print(\"Training Naive Bayes model. It may takes some time\")\n",
    "        self.build_word_counts_model(files_path)\n",
    "        self.save_model_to_file(model_file)\n",
    "    \n",
    "    def load_model_from_file(self,file_name):\n",
    "        with open(file_name,'r',encoding=\"latin1\") as filehandle:\n",
    "            model = json.load(filehandle,encoding = \"ISO-8859-1\")\n",
    "            self.class_counts = model[\"class_counts\"]\n",
    "        self.model_vocabulary_size = len(self.class_counts.get('spam').get('word_counts')) + len(self.class_counts.get('notspam').get('word_counts'))\n",
    "    \n",
    "    def get_word_presence_class_log_prob(self, word, output_class):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return log(float(self.class_counts[output_class]['word_counts'].get(word, {}).get('presence_count', 0) + 1.0) / \\\n",
    "                       (self.class_counts[output_class]['total_count'] + self.model_vocabulary_size))\n",
    "    \n",
    "    def get_word_frequency_class_log_prob(self, word, output_class):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return log(float(self.class_counts[output_class]['word_counts'].get(word,{}).get('frequency_count',0) + 1.0)/\\\n",
    "                (self.class_counts[output_class]['total_count'] + self.model_vocabulary_size))\n",
    "    \n",
    "    def get_class_prob(self, output_class):\n",
    "        total_count = 0\n",
    "        for key in self.class_counts.keys():\n",
    "            total_count = total_count + self.class_counts[key]['total_count']\n",
    "        return log(float(self.class_counts[output_class]['total_count'])/\\\n",
    "            (total_count))\n",
    "    \n",
    "    def predict_simple(self, document):\n",
    "        with open(document, 'r', encoding = \"latin1\") as f:\n",
    "            contents = f.read()\n",
    "            words = set(contents.split())\n",
    "            max_prob = -sys.maxsize\n",
    "            max_class = None\n",
    "            for output_class in ('spam', 'notspam'):\n",
    "                p = self.get_class_prob(output_class)\n",
    "                for word in words:\n",
    "                    p = p + self.get_word_presence_class_log_prob(word, output_class)\n",
    "                if p > max_prob:\n",
    "                    max_prob = p\n",
    "                    max_class = output_class\n",
    "            return max_class\n",
    "    \n",
    "    def predict_with_word_frequencies(self, document):\n",
    "        with open(document, 'r', encoding = \"latin1\") as f:\n",
    "            contents = f.read()\n",
    "            words = contents.split()\n",
    "            max_prob = -sys.maxsize\n",
    "            max_class = None\n",
    "            for output_class in ('spam', 'notspam'):\n",
    "                p = self.get_class_prob(output_class)\n",
    "                for word in words:\n",
    "                    p = p + self.get_word_frequency_class_log_prob(word, output_class)\n",
    "                if p > max_prob:\n",
    "                    max_prob = p\n",
    "                    max_class = output_class\n",
    "            return max_class\n",
    "    \n",
    "    def predict(self, files_path, model_file):\n",
    "        self.load_model_from_file(model_file)\n",
    "        dirs = os.listdir(files_path)\n",
    "        print (\"##### Making predictions with the words presence in the model... #####\")\n",
    "        for class_dir_name in dirs:\n",
    "            total_test_cases = 0\n",
    "            correct_predictions = 0\n",
    "            for f in os.listdir(os.path.join(files_path, class_dir_name)):\n",
    "                document = os.path.join(files_path, class_dir_name, f)\n",
    "                total_test_cases += 1\n",
    "                predicted_class = self.predict_simple(document)\n",
    "                if predicted_class == class_dir_name:\n",
    "                    correct_predictions += 1\n",
    "            print (\"Presence Accuracy of the class: %s \" % class_dir_name)\n",
    "            print (\"### Total observations: %d  \" % (total_test_cases))\n",
    "            print (\"### Correct class observations: %d  \" % (correct_predictions))\n",
    "            print (\"### accuracy: %.2f  \" % (float(correct_predictions) / total_test_cases))\n",
    "        print(\"\")\n",
    "        print (\"##### Making predicions with the words frequence in the model... #####\")\n",
    "        for class_dir_name in dirs:\n",
    "            total_test_cases = 0\n",
    "            correct_predictions = 0\n",
    "            for f in os.listdir(os.path.join(files_path, class_dir_name)):\n",
    "                document = os.path.join(files_path, class_dir_name, f)\n",
    "                total_test_cases += 1\n",
    "                predicted_class = self.predict_with_word_frequencies(document)\n",
    "                if predicted_class == class_dir_name:\n",
    "                    correct_predictions += 1\n",
    "            print (\"Presence Accuracy of the class: %s \" % class_dir_name)\n",
    "            print (\"### Total observations: %d  \" % (total_test_cases))\n",
    "            print (\"### Correct class observations: %d  \" % (correct_predictions))\n",
    "            print (\"### accuracy: %.2f  \" % (float(correct_predictions) / total_test_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_NaiveBayes_model(dataset_directory, model_file):\n",
    "    nb = NB_Model()\n",
    "    nb.train(dataset_directory, model_file)\n",
    "\n",
    "def predict_with_NaiveBayes(dataset_directory, model_file):\n",
    "    nb = NB_Model()\n",
    "    nb.predict(dataset_directory, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes model. It may takes some time\n",
      "Counting words in train dataset...\n",
      "Saving model in especified file...\n"
     ]
    }
   ],
   "source": [
    "# treinamento do modelo\n",
    "build_NaiveBayes_model(\"./train/\", \"output/resultado.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Making predictions with the words presence in the model... #####\n",
      "Presence Accuracy of the class: notspam \n",
      "### Total observations: 1369  \n",
      "### Correct class observations: 1353  \n",
      "### accuracy: 0.99  \n",
      "Presence Accuracy of the class: spam \n",
      "### Total observations: 1185  \n",
      "### Correct class observations: 1139  \n",
      "### accuracy: 0.96  \n",
      "\n",
      "##### Making predicions with the words frequence in the model... #####\n",
      "Presence Accuracy of the class: notspam \n",
      "### Total observations: 1369  \n",
      "### Correct class observations: 1348  \n",
      "### accuracy: 0.98  \n",
      "Presence Accuracy of the class: spam \n",
      "### Total observations: 1185  \n",
      "### Correct class observations: 1134  \n",
      "### accuracy: 0.96  \n"
     ]
    }
   ],
   "source": [
    "# teste do modelo\n",
    "predict_with_NaiveBayes(\"./test/\", \"output/resultado.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
